{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5cb84e8",
   "metadata": {},
   "source": [
    "### Nous allons ici faire quelques applications d'augmentation des données textuelles en suivant un tutoriel sur medium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73361097",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nlpaug\n",
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87df1a7",
   "metadata": {},
   "source": [
    "Version de PyTorch qui sera compatible avec CUDA 12.2 que nous avons utilisé "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92a995b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.6.0+cpu\n",
      "Uninstalling torch-2.6.0+cpu:\n",
      "  Successfully uninstalled torch-2.6.0+cpu\n",
      "Found existing installation: torchvision 0.20.1+cu121\n",
      "Uninstalling torchvision-0.20.1+cu121:\n",
      "  Successfully uninstalled torchvision-0.20.1+cu121\n",
      "Found existing installation: torchaudio 2.5.1+cu121\n",
      "Uninstalling torchaudio-2.5.1+cu121:\n",
      "  Successfully uninstalled torchaudio-2.5.1+cu121\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch==2.5.1+cu121\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.4 MB)\n",
      "Collecting torchvision==0.20.1+cu121\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
      "Collecting torchaudio==2.5.1\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
      "Requirement already satisfied: filelock in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (4.14.1)\n",
      "Requirement already satisfied: networkx in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torch==2.5.1+cu121) (1.13.1)\n",
      "Requirement already satisfied: numpy in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torchvision==0.20.1+cu121) (2.3.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from torchvision==0.20.1+cu121) (11.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.5.1+cu121) (12.8.93)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.5.1+cu121) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/rosalie/miniforge3/lib/python3.12/site-packages (from jinja2->torch==2.5.1+cu121) (3.0.2)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torch torchvision torchaudio\n",
    "!pip install torch==2.5.1+cu121 torchvision==0.20.1+cu121 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f4c2112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4a1ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Un exemple de texte qu'on veut reformuler \n",
    "text = \"The quick brown fox jumps over a lazy dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04b61473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, nltk\n",
    "\n",
    "# 1) Dossier local et inscriptible pour les données NLTK\n",
    "NLTK_DIR = os.path.expanduser(\"~/nltk_data\")\n",
    "os.makedirs(NLTK_DIR, exist_ok=True)\n",
    "if NLTK_DIR not in nltk.data.path:\n",
    "    nltk.data.path.append(NLTK_DIR)\n",
    "\n",
    "# 2) Téléchargements nécessaires\n",
    "# - wordnet + omw-1.4 : pour les synonymes\n",
    "# - averaged_perceptron_tagger_eng : POS tagger (NLTK 3.8+)\n",
    "# - averaged_perceptron_tagger : par compatibilité descendante (certaines libs le demandent encore)\n",
    "# - punkt : tokenisation de base (utile selon les tokenizers)\n",
    "for pkg in [\"wordnet\", \"omw-1.4\", \"averaged_perceptron_tagger_eng\",\n",
    "            \"averaged_perceptron_tagger\", \"punkt\"]:\n",
    "    try:\n",
    "        nltk.download(pkg, download_dir=NLTK_DIR, quiet=True)\n",
    "    except Exception as e:\n",
    "        print(f\"NLTK download failed for {pkg}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8ec41e",
   "metadata": {},
   "source": [
    "#### Synonym Replacement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "831efad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonym Text:  ['The quick robert brown fox bound over a lazy wienerwurst']\n"
     ]
    }
   ],
   "source": [
    "syn_aug = naw.synonym.SynonymAug(aug_src=\"wordnet\")\n",
    "synonym_text = syn_aug.augment(text)\n",
    "print(\"Synonym Text: \", synonym_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4eb4bc",
   "metadata": {},
   "source": [
    "#### Random Substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a89133a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substituted Text:  ['_ quick brown _ jumps over a lazy _']\n"
     ]
    }
   ],
   "source": [
    "sub_aug = naw.random.RandomWordAug(action='substitute')\n",
    "substituted_text = sub_aug.augment(text)\n",
    "print(\"Substituted Text: \", substituted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c34e66",
   "metadata": {},
   "source": [
    "### Random Deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad081b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deletion Text:  ['The jumps over a lazy dog']\n"
     ]
    }
   ],
   "source": [
    "del_aug = naw.random.RandomWordAug(action='delete')\n",
    "deletion_text = del_aug.augment(text)\n",
    "print(\"Deletion Text: \", deletion_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f062258d",
   "metadata": {},
   "source": [
    "### Random Swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb44cd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swap Text:  ['Quick the brown jumps fox over lazy a dog']\n"
     ]
    }
   ],
   "source": [
    "swap_aug = naw.random.RandomWordAug(action='swap')\n",
    "swap_text = swap_aug.augment(text)\n",
    "print(\"Swap Text: \", swap_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9decddfb",
   "metadata": {},
   "source": [
    "### Back Translation\n",
    "\n",
    "Translate original text to other language (like french) and convert back to english language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a95e1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back Translated Text:  ['The fast brown fox jumps on a lazy dog']\n"
     ]
    }
   ],
   "source": [
    "# on utilise un modèle de traduction anglais-français et français-anglais\n",
    "# pour reformuler le texte en anglais\n",
    "import nlpaug.augmenter.word as naw\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "back_trans_aug = naw.BackTranslationAug(\n",
    "    from_model_name='Helsinki-NLP/opus-mt-en-fr',\n",
    "    to_model_name='Helsinki-NLP/opus-mt-fr-en',\n",
    "    device=device,\n",
    "    max_length=300\n",
    ")\n",
    "\n",
    "back_trans_text = back_trans_aug.augment(text)\n",
    "print(\"Back Translated Text: \", back_trans_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be4111dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rosalie/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['La surveillance syndromique de la santé des plantes est essentielle.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "src_text = [\"Syndromic surveillance in plant health is essential.\"]\n",
    "inputs = tokenizer(src_text, return_tensors=\"pt\", padding=True)\n",
    "translated = model.generate(**inputs)\n",
    "print([tokenizer.decode(t, skip_special_tokens=True) for t in translated])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff9bda2",
   "metadata": {},
   "source": [
    "### Nous allons appliquer la Rétrotraduction pour former notre premier jeu de données augmenté \n",
    "Nous allons appliquer cela sur les données de texte brute ensuite on fera encore le nettoyage, nous allons appliquer l'augmentation uniquement pour les articles de type VS qui est sous représenté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b75e257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, nltk\n",
    "\n",
    "# Dossier local pour les données NLTK (avec droits d’écriture)\n",
    "NLTK_DIR = os.path.expanduser(\"~/nltk_data\")\n",
    "os.makedirs(NLTK_DIR, exist_ok=True)\n",
    "if NLTK_DIR not in nltk.data.path:\n",
    "    nltk.data.path.append(NLTK_DIR)\n",
    "\n",
    "# Paquets requis (NLTK 3.8+)\n",
    "for pkg in [\n",
    "    \"punkt\",                         # tokeniseur historique\n",
    "    \"punkt_tab\",                     # depuis NLTK 3.8\n",
    "    \"stopwords\",\n",
    "    \"wordnet\", \"omw-1.4\",\n",
    "    \"averaged_perceptron_tagger_eng\",\n",
    "    \"averaged_perceptron_tagger\",    # compat descente\n",
    "]:\n",
    "    try:\n",
    "        nltk.download(pkg, download_dir=NLTK_DIR, quiet=True)\n",
    "    except Exception as e:\n",
    "        print(f\"NLTK download failed for {pkg}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af5880",
   "metadata": {},
   "source": [
    "#### Essayons ici de rattraper le nombre d'articles de NVS pour plus d'équilibre au travers de la rétro-traduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f76dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rosalie/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device choisi : cuda\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "facebook/wmt19-en-fr is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/requests/models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 401 Client Error: Unauthorized for url: https://huggingface.co/facebook/wmt19-en-fr/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRepositoryNotFoundError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/transformers/utils/hub.py:399\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    398\u001b[39m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     resolved_file = \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1117\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1658\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1653\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1654\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m   1655\u001b[39m ):\n\u001b[32m   1656\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m   1657\u001b[39m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1658\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[32m   1659\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1660\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1546\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1545\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1546\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1463\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[39m\n\u001b[32m   1462\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1463\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1472\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/file_download.py:310\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    309\u001b[39m response = http_backoff(method=method, url=url, **params, retry_on_exceptions=(), retry_on_status_codes=(\u001b[32m429\u001b[39m,))\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:459\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    450\u001b[39m     message = (\n\u001b[32m    451\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    452\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    457\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m https://huggingface.co/docs/huggingface_hub/authentication\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    458\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m400\u001b[39m:\n",
      "\u001b[31mRepositoryNotFoundError\u001b[39m: 401 Client Error. (Request ID: Root=1-68af1694-24323b5959d9a2a058a9d984;428e5690-8e57-4186-8dea-d9ea0ee85d11)\n\nRepository Not Found for url: https://huggingface.co/facebook/wmt19-en-fr/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDevice choisi :\u001b[39m\u001b[33m\"\u001b[39m, device)\n\u001b[32m     59\u001b[39m from_model, to_model = (\n\u001b[32m     60\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mfacebook/wmt19-en-fr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfacebook/wmt19-fr-en\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m device == \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mHelsinki-NLP/opus-mt-en-fr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mHelsinki-NLP/opus-mt-fr-en\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     62\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m back_trans_aug = \u001b[43mnaw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBackTranslationAug\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mto_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mto_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\n\u001b[32m     70\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# ==== Load data ====\u001b[39;00m\n\u001b[32m     73\u001b[39m df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m./data/data_final_phase2_private.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/nlpaug/augmenter/word/back_translation.py:61\u001b[39m, in \u001b[36mBackTranslationAug.__init__\u001b[39m\u001b[34m(self, from_model_name, to_model_name, name, device, batch_size, max_length, force_reload, verbose)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, from_model_name=\u001b[33m'\u001b[39m\u001b[33mfacebook/wmt19-en-de\u001b[39m\u001b[33m'\u001b[39m, to_model_name=\u001b[33m'\u001b[39m\u001b[33mfacebook/wmt19-de-en\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     56\u001b[39m     name=\u001b[33m'\u001b[39m\u001b[33mBackTranslationAug\u001b[39m\u001b[33m'\u001b[39m, device=\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m, batch_size=\u001b[32m32\u001b[39m, max_length=\u001b[32m300\u001b[39m, force_reload=\u001b[38;5;28;01mFalse\u001b[39;00m, verbose=\u001b[32m0\u001b[39m):\n\u001b[32m     57\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m     58\u001b[39m         action=\u001b[33m'\u001b[39m\u001b[33msubstitute\u001b[39m\u001b[33m'\u001b[39m, name=name, aug_p=\u001b[38;5;28;01mNone\u001b[39;00m, aug_min=\u001b[38;5;28;01mNone\u001b[39;00m, aug_max=\u001b[38;5;28;01mNone\u001b[39;00m, tokenizer=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     59\u001b[39m         device=device, verbose=verbose, include_detail=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrom_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mto_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28mself\u001b[39m.device = \u001b[38;5;28mself\u001b[39m.model.device\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/nlpaug/augmenter/word/back_translation.py:76\u001b[39m, in \u001b[36mBackTranslationAug.get_model\u001b[39m\u001b[34m(cls, from_model_name, to_model_name, device, force_reload, batch_size, max_length)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_model\u001b[39m(\u001b[38;5;28mcls\u001b[39m, from_model_name, to_model_name, device=\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m, force_reload=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     75\u001b[39m               batch_size=\u001b[32m32\u001b[39m, max_length=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minit_back_translation_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrom_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/nlpaug/augmenter/word/back_translation.py:25\u001b[39m, in \u001b[36minit_back_translation_model\u001b[39m\u001b[34m(from_model_name, to_model_name, device, force_reload, batch_size, max_length)\u001b[39m\n\u001b[32m     21\u001b[39m     BACK_TRANSLATION_MODELS[model_name].max_length = max_length\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m BACK_TRANSLATION_MODELS[model_name]\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m model = \u001b[43mnml\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMtTransformers\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mto_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m BACK_TRANSLATION_MODELS[model_name] = model\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/nlpaug/model/lang_models/machine_translation_transformers.py:23\u001b[39m, in \u001b[36mMtTransformers.__init__\u001b[39m\u001b[34m(self, src_model_name, tgt_model_name, device, silence, batch_size, max_length)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mself\u001b[39m.src_model_name = src_model_name\n\u001b[32m     22\u001b[39m \u001b[38;5;28mself\u001b[39m.tgt_model_name = tgt_model_name\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28mself\u001b[39m.src_model = \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msrc_model_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mself\u001b[39m.src_model.eval()\n\u001b[32m     25\u001b[39m \u001b[38;5;28mself\u001b[39m.src_model.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:484\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[32m    483\u001b[39m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m         resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    492\u001b[39m         commit_hash = extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/transformers/utils/hub.py:422\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m    418\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMake sure to have access to it at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    419\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    420\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m    423\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a local folder and is not a valid model identifier \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    424\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlisted on \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/models\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    425\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    426\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`token=<your_token>`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    427\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m    430\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    431\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfor this model name. Check the model page at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    432\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m for available revisions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    433\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: facebook/wmt19-en-fr is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nlpaug.augmenter.word as naw\n",
    "from typing import Optional, List\n",
    "import torch, re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "import os\n",
    "import math\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "# ==== Init NLTK stuff ====\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "custom_stopwords = {'et', 'al'}\n",
    "\n",
    "# ==== Utils ====\n",
    "def coerce_to_str(x) -> str:\n",
    "    if isinstance(x, list):\n",
    "        x = \" \".join(map(str, x))\n",
    "    elif pd.isna(x):\n",
    "        x = \"\"\n",
    "    return str(x).strip()\n",
    "\n",
    "def safe_augment(aug, text: str, n: int = 1) -> List[str]:\n",
    "    \"\"\"Retourne une liste de n paraphrases (peut être < n si le modèle échoue).\"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    try:\n",
    "        out = aug.augment(text, n=n)  # peut renvoyer str ou list[str]\n",
    "        if isinstance(out, str):\n",
    "            out = [out]\n",
    "        return [t.strip() for t in out if isinstance(t, str) and t.strip()]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def nettoyer_texte_tokens(texte: str) -> List[str]:\n",
    "    tokens = word_tokenize(texte)\n",
    "    tokens_nettoyes = []\n",
    "    for token in tokens:\n",
    "        token = token.lower()\n",
    "        token = re.sub(r'\\s+', '', token)\n",
    "        token = re.sub(r'[^a-zàâçéèêëîïôûùüÿñæœ]', '', token)\n",
    "        if token and token not in stop_words and token not in punctuation and token not in custom_stopwords:\n",
    "            token = lemmatizer.lemmatize(token)\n",
    "            tokens_nettoyes.append(token)\n",
    "    return tokens_nettoyes\n",
    "\n",
    "def tokens_to_text(tokens: List[str]) -> str:\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# ==== Device & models ====\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device choisi :\", device)\n",
    "\n",
    "from_model, to_model = (\n",
    "    (\"facebook/wmt19-en-fr\", \"facebook/wmt19-fr-en\") if device == \"cuda\"\n",
    "    else (\"Helsinki-NLP/opus-mt-en-fr\", \"Helsinki-NLP/opus-mt-fr-en\")\n",
    ")\n",
    "\n",
    "back_trans_aug = naw.BackTranslationAug(\n",
    "    from_model_name=from_model,\n",
    "    to_model_name=to_model,\n",
    "    device=device,\n",
    "    batch_size=32 if device == \"cuda\" else 8,\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "# ==== Load data ====\n",
    "df = pd.read_csv(\"./data/data_final_phase2_private.csv\")\n",
    "df[\"text\"] = df[\"text\"].apply(coerce_to_str)\n",
    "\n",
    "# (Re)crée text_clean / token_clean si manquants\n",
    "if \"token_clean\" not in df.columns:\n",
    "    df[\"token_clean\"] = df[\"text\"].apply(nettoyer_texte_tokens)\n",
    "else:\n",
    "    mask = df[\"token_clean\"].isna()\n",
    "    df.loc[mask, \"token_clean\"] = df.loc[mask, \"text\"].apply(nettoyer_texte_tokens)\n",
    "\n",
    "if \"text_clean\" not in df.columns:\n",
    "    df[\"text_clean\"] = df[\"token_clean\"].apply(tokens_to_text)\n",
    "else:\n",
    "    mask = df[\"text_clean\"].isna()\n",
    "    df.loc[mask, \"text_clean\"] = df.loc[mask, \"token_clean\"].apply(tokens_to_text)\n",
    "\n",
    "# ==== Filtrer uniquement la classe VS ====\n",
    "\n",
    "mask_vs = df[\"type_article\"].astype(str).str.upper().eq(\"VS\")\n",
    "df_vs = df[mask_vs].copy()\n",
    "\n",
    "\n",
    "\n",
    "# --- Comptage ---\n",
    "count_vs  = (df[\"type_article\"].astype(str).str.upper() == \"VS\").sum()\n",
    "count_nvs = (df[\"type_article\"].astype(str).str.upper() == \"NVS\").sum()\n",
    "print(\"NVS:\", count_nvs, \" VS:\", count_vs)\n",
    "\n",
    "target = count_nvs\n",
    "needed = max(0, target - count_vs)\n",
    "if needed == 0:\n",
    "    print(\"Pas besoin d'augmentation: VS est déjà ≥ NVS.\")\n",
    "\n",
    "# --- Génération ---\n",
    "aug_rows = []\n",
    "if needed > 0:\n",
    "    factor = math.ceil(target / count_vs)  # nb total de versions par article (original compris)\n",
    "    print(f\"Chaque article VS doit produire à peu près {factor} versions (dont l'original).\")\n",
    "\n",
    "    for _, row in df_vs.iterrows():\n",
    "        raw = row[\"text\"]\n",
    "        aug_texts = safe_augment(back_trans_aug, raw[:2000], n=max(1, factor-1))\n",
    "        # construire les lignes\n",
    "        for aug_text in aug_texts:\n",
    "            tokens_bt = nettoyer_texte_tokens(aug_text)\n",
    "            aug_rows.append({\n",
    "                \"text_src\": raw,\n",
    "                \"text_final\": aug_text,\n",
    "                \"source\": \"bt\",\n",
    "                \"token_clean\": tokens_bt,\n",
    "                \"text_clean\": tokens_to_text(tokens_bt),\n",
    "                \"type_article\": row[\"type_article\"],\n",
    "                \"thematique\": row.get(\"thematique\", \"\")\n",
    "            })\n",
    "\n",
    "# DataFrame des augmentées\n",
    "aug_df = pd.DataFrame(aug_rows)\n",
    "\n",
    "# --- Déduplication robuste ---\n",
    "# 1) enlever les lignes vides/NaN\n",
    "aug_df = aug_df[aug_df[\"text_final\"].astype(str).str.strip().ne(\"\")].dropna(subset=[\"text_final\"])\n",
    "\n",
    "# 2) dédupliquer par paraphrase (et étiquette) pour éviter redites exactes\n",
    "aug_df = aug_df.drop_duplicates(subset=[\"text_final\", \"type_article\"], keep=\"first\")\n",
    "\n",
    "# 3) si trop de lignes, échantillonner pour viser exactement \"needed\"\n",
    "if len(aug_df) > needed:\n",
    "    # Utilisons random_sate pour controler l'aléa \n",
    "    aug_df = aug_df.sample(n=needed, random_state=42).reset_index(drop=True)\n",
    "elif len(aug_df) < needed:\n",
    "    print(f\"Seulement {len(aug_df)} paraphrases uniques générées, < needed={needed}.\")\n",
    "  \n",
    "\n",
    "print(\"Articles VS générés (uniques) :\", len(aug_df))\n",
    "print(\"Total VS (original + aug) :\", count_vs + len(aug_df))\n",
    "print(\"Total NVS :\", count_nvs)\n",
    "\n",
    "# --- Bloc original & concat finale ---\n",
    "train_original = df.copy()\n",
    "train_original[\"text_src\"]   = train_original[\"text\"]\n",
    "train_original[\"text_final\"] = train_original[\"text\"]\n",
    "train_original[\"source\"]     = \"orig\"\n",
    "\n",
    "cols = [\"text_final\", \"text_clean\", \"token_clean\", \"source\", \"type_article\", \"thematique\", \"text_src\"]\n",
    "\n",
    "def ensure_list(x):\n",
    "    if isinstance(x, list): return x\n",
    "    if isinstance(x, str):  return x.split()\n",
    "    return []\n",
    "\n",
    "train_original = train_original.reindex(columns=cols, fill_value=\"\")\n",
    "train_original[\"token_clean\"] = train_original[\"token_clean\"].apply(ensure_list)\n",
    "train_original[\"text_clean\"]  = train_original[\"text_clean\"].astype(str)\n",
    "\n",
    "train_aug = aug_df.reindex(columns=cols, fill_value=\"\")\n",
    "\n",
    "train_data = pd.concat([train_original, train_aug], ignore_index=True)\n",
    "print(\"Nb lignes original :\", len(df))\n",
    "print(\"Nb VS augmentées   :\", len(aug_df))\n",
    "print(\"Taille finale       :\", train_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d84efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.5.1+cu121\n",
      "CUDA dispo: True\n",
      "GPU count: 1\n",
      "Nom du GPU: NVIDIA RTX 4500 Ada Generation\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA dispo:\", torch.cuda.is_available())\n",
    "print(\"GPU count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Nom du GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2551be81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_final</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>token_clean</th>\n",
       "      <th>source</th>\n",
       "      <th>type_article</th>\n",
       "      <th>thematique</th>\n",
       "      <th>text_src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microbial Community Composition Associated wit...</td>\n",
       "      <td>microbial community composition associated pot...</td>\n",
       "      <td>[microbial, community, composition, associated...</td>\n",
       "      <td>orig</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Microbial Community Composition Associated wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plant Pathogenic and Endophytic Colletotrichum...</td>\n",
       "      <td>plant pathogenic endophytic colletotrichum fru...</td>\n",
       "      <td>[plant, pathogenic, endophytic, colletotrichum...</td>\n",
       "      <td>orig</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Plant Pathogenic and Endophytic Colletotrichum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lethal Bronzing: What you should know about th...</td>\n",
       "      <td>lethal bronzing know disease turn palm tree br...</td>\n",
       "      <td>[lethal, bronzing, know, disease, turn, palm, ...</td>\n",
       "      <td>orig</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Lethal Bronzing: What you should know about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leaffooted Bug Damage in Almond Orchards Leaff...</td>\n",
       "      <td>leaffooted bug damage almond orchard leaffoote...</td>\n",
       "      <td>[leaffooted, bug, damage, almond, orchard, lea...</td>\n",
       "      <td>orig</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Leaffooted Bug Damage in Almond Orchards Leaff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kebbi govt battles mysterious disease affectin...</td>\n",
       "      <td>kebbi govt battle mysterious disease affecting...</td>\n",
       "      <td>[kebbi, govt, battle, mysterious, disease, aff...</td>\n",
       "      <td>orig</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Kebbi govt battles mysterious disease affectin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>In the case of Alabama, mysterious seeds shoul...</td>\n",
       "      <td>case alabama mysterious seed represent agricul...</td>\n",
       "      <td>[case, alabama, mysterious, seed, represent, a...</td>\n",
       "      <td>bt</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Mystery Seed Packages Appearing Once Again in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>According to the Ministry of Agriculture and I...</td>\n",
       "      <td>according ministry agriculture industry alabam...</td>\n",
       "      <td>[according, ministry, agriculture, industry, a...</td>\n",
       "      <td>bt</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>ACES: Mystery seed packages appearing once aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>In the case of farmers, there is an unpreceden...</td>\n",
       "      <td>case farmer unprecedented increase price fresh...</td>\n",
       "      <td>[case, farmer, unprecedented, increase, price,...</td>\n",
       "      <td>bt</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Farmers Blame Unknown Pest As Pepper Hits ₦150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>A sharp drop in yield as the mysterious fungal...</td>\n",
       "      <td>sharp drop yield mysterious fungal infection a...</td>\n",
       "      <td>[sharp, drop, yield, mysterious, fungal, infec...</td>\n",
       "      <td>bt</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Sharp decline in yield as mysterious fungal in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>The SLP appears as round or oval lesions that ...</td>\n",
       "      <td>slp appears round oval lesion may yellow white...</td>\n",
       "      <td>[slp, appears, round, oval, lesion, may, yello...</td>\n",
       "      <td>bt</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Physiological leaf spot suspected in southern ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2739 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_final  \\\n",
       "0     Microbial Community Composition Associated wit...   \n",
       "1     Plant Pathogenic and Endophytic Colletotrichum...   \n",
       "2     Lethal Bronzing: What you should know about th...   \n",
       "3     Leaffooted Bug Damage in Almond Orchards Leaff...   \n",
       "4     Kebbi govt battles mysterious disease affectin...   \n",
       "...                                                 ...   \n",
       "2734  In the case of Alabama, mysterious seeds shoul...   \n",
       "2735  According to the Ministry of Agriculture and I...   \n",
       "2736  In the case of farmers, there is an unpreceden...   \n",
       "2737  A sharp drop in yield as the mysterious fungal...   \n",
       "2738  The SLP appears as round or oval lesions that ...   \n",
       "\n",
       "                                             text_clean  \\\n",
       "0     microbial community composition associated pot...   \n",
       "1     plant pathogenic endophytic colletotrichum fru...   \n",
       "2     lethal bronzing know disease turn palm tree br...   \n",
       "3     leaffooted bug damage almond orchard leaffoote...   \n",
       "4     kebbi govt battle mysterious disease affecting...   \n",
       "...                                                 ...   \n",
       "2734  case alabama mysterious seed represent agricul...   \n",
       "2735  according ministry agriculture industry alabam...   \n",
       "2736  case farmer unprecedented increase price fresh...   \n",
       "2737  sharp drop yield mysterious fungal infection a...   \n",
       "2738  slp appears round oval lesion may yellow white...   \n",
       "\n",
       "                                            token_clean source type_article  \\\n",
       "0     [microbial, community, composition, associated...   orig           VS   \n",
       "1     [plant, pathogenic, endophytic, colletotrichum...   orig           VS   \n",
       "2     [lethal, bronzing, know, disease, turn, palm, ...   orig           VS   \n",
       "3     [leaffooted, bug, damage, almond, orchard, lea...   orig           VS   \n",
       "4     [kebbi, govt, battle, mysterious, disease, aff...   orig           VS   \n",
       "...                                                 ...    ...          ...   \n",
       "2734  [case, alabama, mysterious, seed, represent, a...     bt           VS   \n",
       "2735  [according, ministry, agriculture, industry, a...     bt           VS   \n",
       "2736  [case, farmer, unprecedented, increase, price,...     bt           VS   \n",
       "2737  [sharp, drop, yield, mysterious, fungal, infec...     bt           VS   \n",
       "2738  [slp, appears, round, oval, lesion, may, yello...     bt           VS   \n",
       "\n",
       "     thematique                                           text_src  \n",
       "0            SV  Microbial Community Composition Associated wit...  \n",
       "1            SV  Plant Pathogenic and Endophytic Colletotrichum...  \n",
       "2            SV  Lethal Bronzing: What you should know about th...  \n",
       "3            SV  Leaffooted Bug Damage in Almond Orchards Leaff...  \n",
       "4            SV  Kebbi govt battles mysterious disease affectin...  \n",
       "...         ...                                                ...  \n",
       "2734         SV  Mystery Seed Packages Appearing Once Again in ...  \n",
       "2735         SV  ACES: Mystery seed packages appearing once aga...  \n",
       "2736         SV  Farmers Blame Unknown Pest As Pepper Hits ₦150...  \n",
       "2737         SV  Sharp decline in yield as mysterious fungal in...  \n",
       "2738         SV  Physiological leaf spot suspected in southern ...  \n",
       "\n",
       "[2739 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a58f4b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"text_final\"].iloc[2735] == train_data[\"text_src\"].iloc[2735]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7966f22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type_article\n",
       "NVS    2241\n",
       "VS      496\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"type_article\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5dd94dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type_article\n",
       "NVS    2241\n",
       "VS      249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"type_article\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5284e3e",
   "metadata": {},
   "source": [
    "#### Les textes augmentées par la rétro traduction ont une source bt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8a46c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sauvegardons les données augmentées dans un fichier csv \n",
    "\n",
    "train_data.to_csv(\"./data/data_augmented_back_translation.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c982ca27",
   "metadata": {},
   "source": [
    "###  Nous allons reprendre la classification avec le fine-tuning de SBERT que nous avons fait à la phase 3 \n",
    "\n",
    "voir le fichier notebook *fine_tuning_experiments_augmentated.ipynb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4058528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv(\"./data/data_augmented_back_translation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07c46c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_final</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>token_clean</th>\n",
       "      <th>source</th>\n",
       "      <th>type_article</th>\n",
       "      <th>thematique</th>\n",
       "      <th>text_src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microbial Community Composition Associated wit...</td>\n",
       "      <td>microbial community composition associated pot...</td>\n",
       "      <td>['microbial', 'community', 'composition', 'ass...</td>\n",
       "      <td>orig</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Microbial Community Composition Associated wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plant Pathogenic and Endophytic Colletotrichum...</td>\n",
       "      <td>plant pathogenic endophytic colletotrichum fru...</td>\n",
       "      <td>['plant', 'pathogenic', 'endophytic', 'colleto...</td>\n",
       "      <td>orig</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Plant Pathogenic and Endophytic Colletotrichum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lethal Bronzing: What you should know about th...</td>\n",
       "      <td>lethal bronzing know disease turn palm tree br...</td>\n",
       "      <td>['lethal', 'bronzing', 'know', 'disease', 'tur...</td>\n",
       "      <td>orig</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Lethal Bronzing: What you should know about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leaffooted Bug Damage in Almond Orchards Leaff...</td>\n",
       "      <td>leaffooted bug damage almond orchard leaffoote...</td>\n",
       "      <td>['leaffooted', 'bug', 'damage', 'almond', 'orc...</td>\n",
       "      <td>orig</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Leaffooted Bug Damage in Almond Orchards Leaff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kebbi govt battles mysterious disease affectin...</td>\n",
       "      <td>kebbi govt battle mysterious disease affecting...</td>\n",
       "      <td>['kebbi', 'govt', 'battle', 'mysterious', 'dis...</td>\n",
       "      <td>orig</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Kebbi govt battles mysterious disease affectin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>Mystery Seed Packages Appearing Once Again in ...</td>\n",
       "      <td>mystery seed package appearing alabama mystery...</td>\n",
       "      <td>['mystery', 'seed', 'package', 'appearing', 'a...</td>\n",
       "      <td>bt</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Mystery Seed Packages Appearing Once Again in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>ACES: Mystery seed packages appeared again in ...</td>\n",
       "      <td>ace mystery seed package appeared alabama ace ...</td>\n",
       "      <td>['ace', 'mystery', 'seed', 'package', 'appeare...</td>\n",
       "      <td>bt</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>ACES: Mystery seed packages appearing once aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>Farmers blame the plague: 150,000 per bag Farm...</td>\n",
       "      <td>farmer blame plague per bag farmer blame plagu...</td>\n",
       "      <td>['farmer', 'blame', 'plague', 'per', 'bag', 'f...</td>\n",
       "      <td>bt</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Farmers Blame Unknown Pest As Pepper Hits ₦150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>Sharp drop in yield due to mysterious fungal i...</td>\n",
       "      <td>sharp drop yield due mysterious fungal infecti...</td>\n",
       "      <td>['sharp', 'drop', 'yield', 'due', 'mysterious'...</td>\n",
       "      <td>bt</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Sharp decline in yield as mysterious fungal in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>According to Prairie Crop Disease Disease Moni...</td>\n",
       "      <td>according prairie crop disease disease monitor...</td>\n",
       "      <td>['according', 'prairie', 'crop', 'disease', 'd...</td>\n",
       "      <td>bt</td>\n",
       "      <td>VS</td>\n",
       "      <td>SV</td>\n",
       "      <td>Physiological leaf spot suspected in southern ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2737 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_final  \\\n",
       "0     Microbial Community Composition Associated wit...   \n",
       "1     Plant Pathogenic and Endophytic Colletotrichum...   \n",
       "2     Lethal Bronzing: What you should know about th...   \n",
       "3     Leaffooted Bug Damage in Almond Orchards Leaff...   \n",
       "4     Kebbi govt battles mysterious disease affectin...   \n",
       "...                                                 ...   \n",
       "2732  Mystery Seed Packages Appearing Once Again in ...   \n",
       "2733  ACES: Mystery seed packages appeared again in ...   \n",
       "2734  Farmers blame the plague: 150,000 per bag Farm...   \n",
       "2735  Sharp drop in yield due to mysterious fungal i...   \n",
       "2736  According to Prairie Crop Disease Disease Moni...   \n",
       "\n",
       "                                             text_clean  \\\n",
       "0     microbial community composition associated pot...   \n",
       "1     plant pathogenic endophytic colletotrichum fru...   \n",
       "2     lethal bronzing know disease turn palm tree br...   \n",
       "3     leaffooted bug damage almond orchard leaffoote...   \n",
       "4     kebbi govt battle mysterious disease affecting...   \n",
       "...                                                 ...   \n",
       "2732  mystery seed package appearing alabama mystery...   \n",
       "2733  ace mystery seed package appeared alabama ace ...   \n",
       "2734  farmer blame plague per bag farmer blame plagu...   \n",
       "2735  sharp drop yield due mysterious fungal infecti...   \n",
       "2736  according prairie crop disease disease monitor...   \n",
       "\n",
       "                                            token_clean source type_article  \\\n",
       "0     ['microbial', 'community', 'composition', 'ass...   orig           VS   \n",
       "1     ['plant', 'pathogenic', 'endophytic', 'colleto...   orig           VS   \n",
       "2     ['lethal', 'bronzing', 'know', 'disease', 'tur...   orig           VS   \n",
       "3     ['leaffooted', 'bug', 'damage', 'almond', 'orc...   orig           VS   \n",
       "4     ['kebbi', 'govt', 'battle', 'mysterious', 'dis...   orig           VS   \n",
       "...                                                 ...    ...          ...   \n",
       "2732  ['mystery', 'seed', 'package', 'appearing', 'a...     bt           VS   \n",
       "2733  ['ace', 'mystery', 'seed', 'package', 'appeare...     bt           VS   \n",
       "2734  ['farmer', 'blame', 'plague', 'per', 'bag', 'f...     bt           VS   \n",
       "2735  ['sharp', 'drop', 'yield', 'due', 'mysterious'...     bt           VS   \n",
       "2736  ['according', 'prairie', 'crop', 'disease', 'd...     bt           VS   \n",
       "\n",
       "     thematique                                           text_src  \n",
       "0            SV  Microbial Community Composition Associated wit...  \n",
       "1            SV  Plant Pathogenic and Endophytic Colletotrichum...  \n",
       "2            SV  Lethal Bronzing: What you should know about th...  \n",
       "3            SV  Leaffooted Bug Damage in Almond Orchards Leaff...  \n",
       "4            SV  Kebbi govt battles mysterious disease affectin...  \n",
       "...         ...                                                ...  \n",
       "2732         SV  Mystery Seed Packages Appearing Once Again in ...  \n",
       "2733         SV  ACES: Mystery seed packages appearing once aga...  \n",
       "2734         SV  Farmers Blame Unknown Pest As Pepper Hits ₦150...  \n",
       "2735         SV  Sharp decline in yield as mysterious fungal in...  \n",
       "2736         SV  Physiological leaf spot suspected in southern ...  \n",
       "\n",
       "[2737 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5936c42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type_article\n",
       "NVS    2241\n",
       "VS      496\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"type_article\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
